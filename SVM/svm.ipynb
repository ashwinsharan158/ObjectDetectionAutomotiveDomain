{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import hog\n",
    "from scipy.ndimage.measurements import label\n",
    "import pickle\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = 32\n",
    "hist_bins = 32\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "spatial_size= (32, 32)\n",
    "object = 'car'\n",
    "ystart_ystop_scale = [(405, 510, 1), (400, 600, 1.5), (500, 710, 2.5)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "neg_images = []\n",
    "for root, dirs, files in os.walk('./data/' + object + '/'):\n",
    "    for file in files:\n",
    "        if file.endswith('.png') or file.endswith('.jpg'):\n",
    "            images.append(os.path.join(root, file))\n",
    "            \n",
    "for root, dirs, files in os.walk('./data/neg/'):\n",
    "    for file in files:\n",
    "        if file.endswith('.png') or file.endswith('.jpg'):\n",
    "            neg_images.append(os.path.join(root, file))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features extract functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute binned color features by scaling images down \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    return features\n",
    "\n",
    "# Compute color histogram features  \n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    return hist_features\n",
    "\n",
    "\n",
    "# Return HOG features\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, feature_vec=True):\n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "# Extract feature wrapper that extracts and combines all features\n",
    "def extract_features(imgs, orient=9, pix_per_cell=8, cell_per_block=2, spatial_size=(32, 32), hist_bins=32, hist_range=(0, 256)):\n",
    "\n",
    "    features = []\n",
    "    for file in imgs:\n",
    "        image = mpimg.imread(file)\n",
    "            \n",
    "        feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "\n",
    "        hog_features = []\n",
    "        for channel in range(feature_image.shape[2]):\n",
    "            hog_features.append(get_hog_features(feature_image[:,:,channel], orient, pix_per_cell, cell_per_block, feature_vec=True))\n",
    "        hog_features = np.ravel(hog_features)\n",
    "        \n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range)\n",
    "        features.append(np.concatenate((spatial_features, hist_features, hog_features)))\n",
    "    return features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_features = extract_features(images, orient=orient, pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        spatial_size=(spatial, spatial), hist_bins=hist_bins, hist_range=(0, 256))\n",
    "\n",
    "neg_images_features = extract_features(neg_images,orient=orient, pix_per_cell=pix_per_cell, cell_per_block=cell_per_block, \n",
    "                        spatial_size=(spatial, spatial), hist_bins=hist_bins, hist_range=(0, 256))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_state = np.random.randint(0, 100)\n",
    "X = np.vstack((images_features, neg_images_features)).astype(np.float64)        \n",
    "X_scaler = StandardScaler().fit(X)\n",
    "scaled_X = X_scaler.transform(X)\n",
    "y = np.hstack((np.ones(len(images_features)), np.zeros(len(neg_images_features))))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "print('Feature vector length:', len(X_train[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC()\n",
    "svc.fit(X_train, y_train)\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_pickle = {}\n",
    "dist_pickle[\"svc\"] = svc\n",
    "dist_pickle[\"scaler\"] = X_scaler\n",
    "dist_pickle[\"orient\"] = orient\n",
    "dist_pickle[\"pix_per_cell\"] = pix_per_cell\n",
    "dist_pickle[\"cell_per_block\"] = cell_per_block\n",
    "dist_pickle[\"spatial\"] = spatial\n",
    "dist_pickle[\"hist_bins\"] = hist_bins\n",
    "pickle.dump(dist_pickle, open(\"svc_pickle_\" + object + \".p\", 'wb') )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_pickle = pickle.load( open(\"svc_pickle_\" + object + \".p\", \"rb\" ) )\n",
    "svc = dist_pickle[\"svc\"]\n",
    "X_scaler = dist_pickle[\"scaler\"]\n",
    "orient = dist_pickle[\"orient\"]\n",
    "pix_per_cell = dist_pickle[\"pix_per_cell\"]\n",
    "cell_per_block = dist_pickle[\"cell_per_block\"]\n",
    "spatia = dist_pickle[\"spatial\"]\n",
    "hist_bins = dist_pickle[\"hist_bins\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hog sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts features using hog sub-sampling and make predictions\n",
    "def find_objs(img, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, ystart_ystop_scale, h_shift=0):\n",
    "    bbox_detection_list=[]\n",
    "    img = img.astype(np.float32)/255\n",
    "\n",
    "    for (ystart, ystop, scale) in ystart_ystop_scale:\n",
    "        img_tosearch = img[ystart:ystop, :, :]\n",
    "        ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2YCrCb)\n",
    "        if scale != 1:\n",
    "            imshape = ctrans_tosearch.shape\n",
    "            ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "\n",
    "        ch1 = ctrans_tosearch[:,:,0]\n",
    "        ch2 = ctrans_tosearch[:,:,1]\n",
    "        ch3 = ctrans_tosearch[:,:,2]\n",
    "        \n",
    "        nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 3\n",
    "        nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "\n",
    "        window = 64\n",
    "        nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "        cells_per_step = 2  \n",
    "        nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "        nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "\n",
    "        hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        for xb in range(nxsteps):\n",
    "            for yb in range(nysteps):\n",
    "                ypos = yb*cells_per_step\n",
    "                xpos = xb*cells_per_step\n",
    "                hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "                xleft = xpos*pix_per_cell\n",
    "                ytop = ypos*pix_per_cell\n",
    "\n",
    "                subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "\n",
    "                spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "                hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "                test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))\n",
    "\n",
    "                test_prediction = svc.predict(test_features)\n",
    "                if test_prediction == 1:\n",
    "                    xbox_left = np.int(xleft*scale)\n",
    "                    ytop_draw = np.int(ytop*scale)\n",
    "                    win_draw = np.int(window*scale)\n",
    "                    bbox_detection_list.append(((xbox_left+h_shift, ytop_draw+ystart),(xbox_left+win_draw+h_shift,ytop_draw+win_draw+ystart)))\n",
    "    return bbox_detection_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulation of labels from last N frames\n",
    "class Detect_history():\n",
    "    def __init__ (self):\n",
    "        self.queue_len = 7\n",
    "        self.queue = []\n",
    "\n",
    "    # Put new frame\n",
    "    def put_labels(self, labels):\n",
    "        if (len(self.queue) > self.queue_len):\n",
    "            tmp = self.queue.pop(0)\n",
    "        self.queue.append(labels)\n",
    "    \n",
    "    # Get last N frames hot boxes\n",
    "    def get_labels(self):\n",
    "        detections = []\n",
    "        for label in self.queue:\n",
    "            detections.extend(label)\n",
    "        return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    for box in bbox_list:\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        cv2.rectangle(img, bbox[0], (bbox[1][0]+10,bbox[1][1]-10), (0,0,255) if object is 'car' else (0,255,0), 2)\n",
    "    return img\n",
    "\n",
    "def process_image(img): \n",
    "    bbox_detection_list = find_objs(img, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, ystart_ystop_scale)\n",
    "    blank = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "\n",
    "    detect_history.put_labels(bbox_detection_list)\n",
    "    bbox_detection_list = detect_history.get_labels()\n",
    "    heatmap = add_heat(blank, bbox_detection_list)\n",
    "    labels = label(heatmap)\n",
    "    result = draw_labeled_bboxes(np.copy(img), labels)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_history = Detect_history()\n",
    "test_images = np.array([plt.imread(i) for i in glob('./data/test_images/*.jpg')])\n",
    "result = process_image(test_images[0])\n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(result)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_history = Detect_history()\n",
    "file_name = 'video'\n",
    "processed_video_path = file_name + '_predict_' + object + '.mp4'\n",
    "video = VideoFileClip(\"./videos/\" + file_name + \".mp4\")\n",
    "processed_video = video.fl_image(process_image)\n",
    "processed_video.write_videofile(processed_video_path, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
